{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyUEF3_ESxm9"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets torchaudio soundfile torchcodec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks2NZkX9di9D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchcodec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWsj5cq3O0iq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEShw4l-vIXI"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "train_ds = load_dataset(\"AbstractTTS/IEMOCAP\", split=\"train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZjEIiDXVdJs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset, Audio\n",
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IEMOCAPAudioDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hf_ds,\n",
        "        threshold=0.05,\n",
        "        disgust_boost=1.0,\n",
        "        fear_surprise_boost=1.0,\n",
        "        anger_shrink=0.9\n",
        "    ):\n",
        "        self.ds = hf_ds\n",
        "        self.threshold = threshold\n",
        "        self.disgust_boost = disgust_boost\n",
        "        self.fear_surprise_boost = fear_surprise_boost\n",
        "        self.anger_shrink = anger_shrink\n",
        "\n",
        "\n",
        "        self.emotion_list = [\n",
        "            \"frustrated\", \"angry\", \"sad\", \"disgust\",\n",
        "            \"excited\", \"fear\", \"neutral\", \"surprise\", \"happy\"\n",
        "        ]\n",
        "\n",
        "\n",
        "        self.target_groups = {\n",
        "            \"angry\": [\"angry\", \"frustrated\"],\n",
        "            \"happy\": [\"happy\", \"excited\"],\n",
        "            \"sad\": [\"sad\"],\n",
        "            \"neutral\": [\"neutral\"],\n",
        "            \"fear_surprise\": [\"fear\", \"surprise\"],\n",
        "            \"disgust\": [\"disgust\"]}\n",
        "\n",
        "        self.output_classes = [\n",
        "            \"angry\",\n",
        "            \"happy\",\n",
        "            \"sad\",\n",
        "            \"neutral\",\n",
        "            \"fear_surprise\",\n",
        "            \"disgust\"\n",
        "        ]\n",
        "\n",
        "        self.emotion_to_index = {cls: i for i, cls in enumerate(self.output_classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.ds[idx]\n",
        "\n",
        "        audio_tensor = torch.tensor(item[\"audio\"][\"array\"], dtype=torch.float32)\n",
        "\n",
        "\n",
        "        merged = []\n",
        "        for group in self.output_classes:\n",
        "            members = self.target_groups[group]\n",
        "            merged_value = sum(float(item[e]) for e in members)\n",
        "            merged.append(merged_value)\n",
        "\n",
        "        merged = torch.tensor(merged, dtype=torch.float32)\n",
        "        # thresholding\n",
        "        mask = merged >= self.threshold\n",
        "        merged = merged * mask.float()\n",
        "\n",
        "        # soft boosting and shrinking the model\n",
        "        merged[self.emotion_to_index[\"angry\"]] *= self.anger_shrink\n",
        "        merged[self.emotion_to_index[\"disgust\"]] *= self.disgust_boost\n",
        "        merged[self.emotion_to_index[\"fear_surprise\"]] *= self.fear_surprise_boost\n",
        "\n",
        "        # normalize\n",
        "        if merged.sum() > 0:\n",
        "            merged = merged / merged.sum()\n",
        "        else:\n",
        "            merged = torch.ones_like(merged) / len(merged)\n",
        "\n",
        "        return audio_tensor, merged\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "processor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
        "    \"facebook/wav2vec2-large\",\n",
        "    cache_dir=\"./hf_cache\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: list of (audio_tensor, label_tensor)\n",
        "    \"\"\"\n",
        "    waveforms, labels = zip(*batch)\n",
        "\n",
        "    waveforms = [w.numpy() for w in waveforms]\n",
        "\n",
        "\n",
        "    inputs = processor(\n",
        "        waveforms,\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    labels = torch.stack(labels)\n",
        "    return inputs[\"input_values\"], labels\n",
        "\n",
        "\n",
        "full_ds = load_dataset(\"AbstractTTS/IEMOCAP\", split=\"train\")\n",
        "\n",
        "split_ds = full_ds.train_test_split(test_size=0.2, seed=42)\n",
        "train_ds_split = split_ds[\"train\"]\n",
        "val_ds_split = split_ds[\"test\"]\n",
        "\n",
        "dataset = IEMOCAPAudioDataset(train_ds_split)\n",
        "val_dataset = IEMOCAPAudioDataset(val_ds_split)\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, # No need to shuffle validation data\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "print(\"âœ“ Dataset + DataLoader ready for split.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_jGlDXAgZtD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC0_fCeleZ9g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcs_6lt6dIwb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
        "# this is a sample that takes a singular waveform and just gets the embedding (no training at all)\n",
        "'''\n",
        "# Load Wav2Vec2\n",
        "processor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large\", cache_dir=\"./hf_cache\")\n",
        "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large\", cache_dir=\"./hf_cache\")\n",
        "model.eval()# delete if we were training it to specifically emotional\n",
        "\n",
        "# Somewhere here we would do stuff like add freeze layers, add layers, etc. etc. etc.\n",
        "# so we would in a training/fine tuning, we would edit model/processor\n",
        "\n",
        "\n",
        "# Forward loop\n",
        "inputs = processor(waveform, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
        "inputs = {k: v for k, v in inputs.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden = model(**inputs).last_hidden_state\n",
        "\n",
        "\n",
        "embedding = hidden.mean(dim=1).squeeze(0)\n",
        "print(\"Embedding shape:\", embedding.shape)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIN15w-3uosx"
      },
      "outputs": [],
      "source": [
        "# figuring out and building the architecture that classifies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AzX9dq1uuSu"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional\n",
        "import torch.nn as nn\n",
        "\n",
        "class EmotionClassifierMLP(nn.Module):\n",
        "    def __init__(self, emb_dim=1024, hidden_dim1=256, hidden_dim2=128, num_classes=9, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(emb_dim, hidden_dim1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, embeddings, return_probs=False):\n",
        "        logits = self.net(embeddings)\n",
        "        if return_probs:\n",
        "            return torch.nn.functional.softmax(logits, dim=-1)\n",
        "        return torch.nn.functional.log_softmax(logits, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6D2RxlmTcB9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\"\"\"\n",
        "# Wav2Vec2 model parameters\n",
        "model_name = \"facebook/wav2vec2-large\"\n",
        "cache_dir = \"./hf_cache\"\n",
        "num_labels = 6  # Number of emotions, corrected from 8 to 9\n",
        "# Wav2Vec2\n",
        "freeze_feature_extractor = True\n",
        "number_unfrozen = 6\n",
        "backbone_learning_rate = 2e-5\n",
        "backbone_weight_decay = 0.0001\n",
        "\n",
        "# Classifier head\n",
        "hidden_dim1 = 256\n",
        "hidden_dim2 = 128\n",
        "dropout = 0.1\n",
        "classifier_learning_rate = 1e-4\n",
        "classifier_weight_decay = 0.0\n",
        "\n",
        "# Training\n",
        "epochs = 15\n",
        "batch_size = 16\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "normalization = False\n",
        "\n",
        "# Schedulers\n",
        "backbone_schedule = \"cosine\"\n",
        "classifier_schedule = \"cosine\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZxp3s4zTeEc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\"\"\"\n",
        "Below is my code for grid searching\n",
        "\n",
        "param_space = {\n",
        "    'number_unfrozen': [0, 3, 6, 9, 12],\n",
        "    'backbone_learning_rate': [1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5],\n",
        "    'classifier_learning_rate': [1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3],\n",
        "    'hidden_dim1': [128, 256, 512],\n",
        "    'hidden_dim2': [64, 128, 256],\n",
        "    'dropout': [0.1, 0.2, 0.3],\n",
        "    'normalization': [True, False]\n",
        "}\n",
        "\n",
        "num_trials = 10\n",
        "epochs_for_grid_search = 7\n",
        "patience_for_grid_search = 3\n",
        "num_labels=9\n",
        "\n",
        "best_accuracy = -1.0\n",
        "best_params = None\n",
        "all_results = []\n",
        "\n",
        "print(f\"Starting Random Grid Search for {num_trials} trials...\")\n",
        "\n",
        "for i in range(num_trials):\n",
        "    print(f\"\\n--- Trial {i+1}/{num_trials} ---\")\n",
        "\n",
        "    # Sample a random combination of hyperparameters\n",
        "    current_params = {\n",
        "        'number_unfrozen': random.choice(param_space['number_unfrozen']),\n",
        "        'backbone_learning_rate': random.choice(param_space['backbone_learning_rate']),\n",
        "        'classifier_learning_rate': random.choice(param_space['classifier_learning_rate']),\n",
        "        'hidden_dim1': random.choice(param_space['hidden_dim1']),\n",
        "        'hidden_dim2': random.choice(param_space['hidden_dim2']),\n",
        "        'dropout': random.choice(param_space['dropout']),\n",
        "        'normalization': random.choice(param_space['normalization'])\n",
        "    }\n",
        "    print(f\"Current parameters: {current_params}\")\n",
        "\n",
        "    # Instantiate the EmotionClassifierMLP with current hyperparameters\n",
        "    classifier_model_trial = EmotionClassifierMLP(\n",
        "        emb_dim=1024,\n",
        "        num_classes=num_labels,\n",
        "        hidden_dim1=current_params['hidden_dim1'],\n",
        "        hidden_dim2=current_params['hidden_dim2'],\n",
        "        dropout=current_params['dropout']\n",
        "    )\n",
        "\n",
        "    # Re-initialize Wav2Vec2EmbeddingExtractor to ensure fresh backbone weights for each trial\n",
        "    wav2vec2_trainer_trial = Wav2Vec2EmbeddingExtractor(\n",
        "        model_name=model_name,\n",
        "        cache_dir=cache_dir\n",
        "    )\n",
        "\n",
        "    val_accuracy = wav2vec2_trainer_trial.train_model(\n",
        "        classification_model=classifier_model_trial,\n",
        "        train_dataloader=train_loader,\n",
        "        val_dataloader=val_loader,\n",
        "        backbone_lr=current_params['backbone_learning_rate'],\n",
        "        classifier_lr=current_params['classifier_learning_rate'],\n",
        "        backbone_weight_decay=backbone_weight_decay,\n",
        "        classifier_weight_decay=classifier_weight_decay,\n",
        "        backbone_schedule=backbone_schedule,\n",
        "        classifier_schedule=classifier_schedule,\n",
        "        number_unfrozen=current_params['number_unfrozen'],\n",
        "        normalization=current_params['normalization'],\n",
        "        epochs=epochs_for_grid_search, # Using the potentially reduced epochs for grid search\n",
        "        device=device,\n",
        "        patience=patience_for_grid_search\n",
        "    )\n",
        "\n",
        "\n",
        "    all_results.append({\n",
        "        'trial': i + 1,\n",
        "        'params': current_params,\n",
        "        'val_accuracy': val_accuracy\n",
        "    })\n",
        "\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        best_params = current_params\n",
        "\n",
        "    print(f\"Trial {i+1} completed. Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\n--- Random Grid Search Summary ---\")\n",
        "print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "print(\"\\nAll trial results:\")\n",
        "for res in all_results:\n",
        "    print(f\"Trial {res['trial']}: Acc={res['val_accuracy']:.4f}, Params={res['params']}\")\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WAVE 2 VEC 2 MLP best Random Search\n",
        "\n",
        "import torch\n",
        "import torchcodec\n",
        "\n",
        "# Wav2Vec2 model parameters\n",
        "model_name = \"facebook/wav2vec2-large\"\n",
        "cache_dir = \"./hf_cache\"\n",
        "num_labels = 6  # Number of emotions, corrected from 8 to 9\n",
        "# Wav2Vec2\n",
        "freeze_feature_extractor = True\n",
        "number_unfrozen = 9\n",
        "backbone_learning_rate = 1e-5\n",
        "backbone_weight_decay = 0.0001\n",
        "\n",
        "# Classifier head\n",
        "hidden_dim1 = 256\n",
        "hidden_dim2 = 64\n",
        "dropout = 0.2\n",
        "classifier_learning_rate = .003\n",
        "classifier_weight_decay = 0.0\n",
        "\n",
        "# Training\n",
        "epochs = 15\n",
        "batch_size = 16\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "normalization = False\n",
        "\n",
        "# Schedulers\n",
        "backbone_schedule = \"cosine\"\n",
        "classifier_schedule = \"cosine\""
      ],
      "metadata": {
        "id": "OijXyhc-yUHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def smooth_inverse_frequency(class_freq, alpha=1.3):\n",
        "\n",
        "    smoothed = 1.0 / torch.log(alpha + class_freq)\n",
        "    smoothed = smoothed / smoothed.mean()\n",
        "    return smoothed\n",
        "\n",
        "\n",
        "class Wav2Vec2EmbeddingExtractor:\n",
        "    def __init__(self, model_name=\"facebook/wav2vec2-large\", cache_dir=\"./hf_cache\"):\n",
        "        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name, cache_dir=cache_dir)\n",
        "        self.model = Wav2Vec2Model.from_pretrained(model_name, cache_dir=cache_dir)\n",
        "\n",
        "    def get_embedding(self, waveform, sampling_rate):\n",
        "\n",
        "        self.model.eval()\n",
        "        inputs = self.processor(waveform, sampling_rate=sampling_rate,\n",
        "                                return_tensors=\"pt\", padding=True)\n",
        "        with torch.no_grad():\n",
        "            hidden = self.model(**inputs).last_hidden_state\n",
        "        return hidden.mean(dim=1).squeeze(0)\n",
        "\n",
        "    def freezing_layers(self, number_unfrozen):\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        total_layers = len(self.model.encoder.layers)\n",
        "        number_unfrozen = min(number_unfrozen, total_layers)\n",
        "\n",
        "        if number_unfrozen > 0:\n",
        "            for layer in self.model.encoder.layers[-number_unfrozen:]:\n",
        "                for p in layer.parameters():\n",
        "                    p.requires_grad = True\n",
        "\n",
        "    def evaluate_model(self, classification_model, dataloader, device):\n",
        "        self.model.eval()\n",
        "        classification_model.eval()\n",
        "        total_major_correct = 0\n",
        "        total_top2_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for input_values, labels in dataloader:\n",
        "                input_values = input_values.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                hidden_states = self.model(input_values).last_hidden_state\n",
        "                batch_embeddings = hidden_states.mean(dim=1)\n",
        "                logits = classification_model(batch_embeddings)\n",
        "\n",
        "                batch_size = input_values.size(0)\n",
        "                pred_major = torch.argmax(logits, dim=1)\n",
        "                true_major = torch.argmax(labels, dim=1)\n",
        "\n",
        "                total_major_correct += (pred_major == true_major).sum().item()\n",
        "\n",
        "                top2_preds = torch.topk(logits, k=2, dim=1).indices\n",
        "                total_top2_correct += sum([\n",
        "                    true_major[i].item() in top2_preds[i].tolist()\n",
        "                    for i in range(batch_size)\n",
        "                ])\n",
        "\n",
        "                total_samples += batch_size\n",
        "\n",
        "        return total_major_correct / total_samples, total_top2_correct / total_samples\n",
        "\n",
        "    def get_predictions(self, classification_model, dataloader, device):\n",
        "        self.model.eval()\n",
        "        classification_model.eval()\n",
        "\n",
        "        true_distributions = []\n",
        "        predicted_distributions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for input_values, labels in dataloader:\n",
        "                input_values = input_values.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                hidden_states = self.model(input_values).last_hidden_state\n",
        "                batch_embeddings = hidden_states.mean(dim=1)\n",
        "\n",
        "                logits = classification_model(batch_embeddings)\n",
        "                probs = F.softmax(logits, dim=1)\n",
        "\n",
        "                predicted_distributions.extend(probs.cpu().tolist())\n",
        "                true_distributions.extend(labels.cpu().tolist())\n",
        "\n",
        "        return {\n",
        "            \"true_distributions\": np.array(true_distributions),\n",
        "            \"predicted_distributions\": np.array(predicted_distributions),\n",
        "        }\n",
        "\n",
        "    def train_model(\n",
        "        self,\n",
        "        classification_model,\n",
        "        train_dataloader,\n",
        "        val_dataloader=None,\n",
        "        backbone_lr=2e-5,\n",
        "        classifier_lr=1e-4,\n",
        "        backbone_weight_decay=0.01,\n",
        "        classifier_weight_decay=0.0,\n",
        "        backbone_schedule=None,\n",
        "        classifier_schedule=None,\n",
        "        number_unfrozen=0,\n",
        "        normalization=False,\n",
        "        epochs=10,\n",
        "        device=\"cpu\",\n",
        "        patience=3,\n",
        "        return_info=False\n",
        "    ):\n",
        "        self.model.to(device)\n",
        "        classification_model.to(device)\n",
        "\n",
        "        self.freezing_layers(number_unfrozen)\n",
        "\n",
        "\n",
        "\n",
        "        num_classes = train_dataloader.dataset.output_classes.__len__()\n",
        "        class_counts = torch.zeros(num_classes)\n",
        "\n",
        "        for _, labels in train_dataloader:\n",
        "            class_counts += labels.sum(dim=0)\n",
        "\n",
        "        class_freq = class_counts / class_counts.sum()\n",
        "        class_freq = class_freq.to(device)\n",
        "\n",
        "\n",
        "        class_weights = smooth_inverse_frequency(class_freq).to(device)\n",
        "        class_weights = class_weights.unsqueeze(0)\n",
        "\n",
        "        print(\"Class frequencies:\", class_freq)\n",
        "        print(\"Smoothed class weights:\", class_weights.squeeze(0))\n",
        "\n",
        "        # Base KL loss\n",
        "        criterion = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
        "\n",
        "        optimizer = torch.optim.AdamW([\n",
        "            {\"params\": filter(lambda p: p.requires_grad, self.model.parameters()),\n",
        "             \"lr\": backbone_lr, \"weight_decay\": backbone_weight_decay},\n",
        "            {\"params\": filter(lambda p: p.requires_grad, classification_model.parameters()),\n",
        "             \"lr\": classifier_lr, \"weight_decay\": classifier_weight_decay}\n",
        "        ])\n",
        "\n",
        "        # Learning rate schedulers\n",
        "        schedulers = []\n",
        "        if backbone_schedule in [\"cosine\", \"linear\"] or classifier_schedule in [\"cosine\", \"linear\"]:\n",
        "            if backbone_schedule == \"cosine\" or classifier_schedule == \"cosine\":\n",
        "                schedulers.append(torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs))\n",
        "            elif backbone_schedule == \"linear\" or classifier_schedule == \"linear\":\n",
        "                schedulers.append(torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5))\n",
        "\n",
        "        best_val_major_acc = -1.0\n",
        "        epochs_no_improve = 0\n",
        "\n",
        "        # Storage lists for metrics\n",
        "        train_losses = []\n",
        "        train_major_accuracies = []\n",
        "        train_top2_accuracies = []\n",
        "        val_major_accuracies = []\n",
        "        val_top2_accuracies = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            classification_model.train()\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            total_major_correct = 0\n",
        "            total_top2_correct = 0\n",
        "            total_samples = 0\n",
        "\n",
        "            for input_values, labels in train_dataloader:\n",
        "                input_values = input_values.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Freeze/unfreeze handling\n",
        "                if number_unfrozen == 0:\n",
        "                    with torch.no_grad():\n",
        "                        hidden_states = self.model(input_values).last_hidden_state\n",
        "                else:\n",
        "                    hidden_states = self.model(input_values).last_hidden_state\n",
        "\n",
        "                batch_embeddings = hidden_states.mean(dim=1)\n",
        "\n",
        "                if normalization:\n",
        "                    batch_embeddings = (\n",
        "                        (batch_embeddings - batch_embeddings.mean(dim=1, keepdim=True)) /\n",
        "                        (batch_embeddings.std(dim=1, keepdim=True) + 1e-7)\n",
        "                    )\n",
        "\n",
        "                logits = classification_model(batch_embeddings)\n",
        "                log_probs = torch.log_softmax(logits, dim=1)\n",
        "\n",
        "                # Apply class weights to label distributions\n",
        "                weighted_labels = labels * class_weights\n",
        "\n",
        "                loss = criterion(log_probs, weighted_labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                batch_size_actual = input_values.size(0)\n",
        "                epoch_loss += loss.item() * batch_size_actual\n",
        "\n",
        "                pred_major = torch.argmax(logits, dim=1)\n",
        "                true_major = torch.argmax(labels, dim=1)\n",
        "                total_major_correct += (pred_major == true_major).sum().item()\n",
        "\n",
        "                top2_preds = torch.topk(logits, k=2, dim=1).indices\n",
        "                total_top2_correct += sum([\n",
        "                    true_major[i].item() in top2_preds[i].tolist()\n",
        "                    for i in range(batch_size_actual)\n",
        "                ])\n",
        "\n",
        "                total_samples += batch_size_actual\n",
        "\n",
        "            # Scheduler update\n",
        "            for scheduler in schedulers:\n",
        "                scheduler.step()\n",
        "\n",
        "            avg_loss = epoch_loss / total_samples\n",
        "            train_major_acc = total_major_correct / total_samples\n",
        "            train_top2_acc = total_top2_correct / total_samples\n",
        "\n",
        "            train_losses.append(avg_loss)\n",
        "            train_major_accuracies.append(train_major_acc)\n",
        "            train_top2_accuracies.append(train_top2_acc)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Loss={avg_loss:.4f} | \"\n",
        "                  f\"Major={train_major_acc:.4f} | Top-2={train_top2_acc:.4f}\")\n",
        "\n",
        "            # Validation\n",
        "            if val_dataloader is not None:\n",
        "                val_major_acc, val_top2_acc = self.evaluate_model(\n",
        "                    classification_model, val_dataloader, device\n",
        "                )\n",
        "\n",
        "                val_major_accuracies.append(val_major_acc)\n",
        "                val_top2_accuracies.append(val_top2_acc)\n",
        "\n",
        "                if val_major_acc > best_val_major_acc:\n",
        "                    best_val_major_acc = val_major_acc\n",
        "                    epochs_no_improve = 0\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "\n",
        "                if epochs_no_improve >= patience:\n",
        "                    break\n",
        "\n",
        "        if return_info:\n",
        "            return (\n",
        "                classification_model,\n",
        "                best_val_major_acc,\n",
        "                train_losses,\n",
        "                train_major_accuracies,\n",
        "                train_top2_accuracies,\n",
        "                val_major_accuracies,\n",
        "                val_top2_accuracies\n",
        "            )\n",
        "        else:\n",
        "            return classification_model, best_val_major_acc\n"
      ],
      "metadata": {
        "id": "CderdSLnqgyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9828534"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "classifier_model = EmotionClassifierMLP(\n",
        "    emb_dim=1024,\n",
        "    num_classes=num_labels,\n",
        "    hidden_dim1=hidden_dim1,\n",
        "    hidden_dim2=hidden_dim2,\n",
        "    dropout=dropout\n",
        ")\n",
        "\n",
        "\n",
        "wav2vec2_trainer = Wav2Vec2EmbeddingExtractor(\n",
        "    model_name=model_name,\n",
        "    cache_dir=cache_dir\n",
        ")\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "\n",
        "\n",
        "print_graphs = True\n",
        "\n",
        "trained_classifier_model, best_val_major_acc, train_losses, train_major_accuracies, train_top2_accuracies, val_major_accuracies, val_top2_accuracies = wav2vec2_trainer.train_model(\n",
        "    classification_model=classifier_model,\n",
        "    train_dataloader=train_loader,\n",
        "    val_dataloader=val_loader,\n",
        "    backbone_lr=backbone_learning_rate,\n",
        "    classifier_lr=classifier_learning_rate,\n",
        "    backbone_weight_decay=backbone_weight_decay,\n",
        "    classifier_weight_decay=classifier_weight_decay,\n",
        "    backbone_schedule=backbone_schedule,\n",
        "    classifier_schedule=classifier_schedule,\n",
        "    number_unfrozen=number_unfrozen,\n",
        "    normalization=normalization,\n",
        "    epochs=epochs,\n",
        "    device=device,\n",
        "    patience=epochs,\n",
        "    return_info=True\n",
        ")\n",
        "\n",
        "print(\"Model training complete.\")\n",
        "print(f\"Best validation major accuracy: {best_val_major_acc:.4f}\")\n",
        "\n",
        "# Get predictions for confusion matrix\n",
        "prediction_and_true = wav2vec2_trainer.get_predictions(trained_classifier_model, val_loader, device)\n",
        "prediction_and_true_train = wav2vec2_trainer.get_predictions(trained_classifier_model, train_loader, device)\n",
        "\n",
        "\n",
        "\n",
        "if print_graphs:\n",
        "    epochs_ran = len(train_losses)\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Plot Training Loss\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(range(1, epochs_ran + 1), train_losses, label='Train Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Training & Validation Major Accuracy\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(range(1, epochs_ran + 1), train_major_accuracies, label='Train Major Accuracy')\n",
        "    if val_major_accuracies:\n",
        "        plt.plot(range(1, epochs_ran + 1), val_major_accuracies, label='Val Major Accuracy')\n",
        "    plt.title('Major Accuracy over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Training & Validation Top-2 Accuracy\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(range(1, epochs_ran + 1), train_top2_accuracies, label='Train Top-2 Accuracy')\n",
        "    if val_top2_accuracies:\n",
        "        plt.plot(range(1, epochs_ran + 1), val_top2_accuracies, label='Val Top-2 Accuracy')\n",
        "    plt.title('Top-2 Accuracy over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "true_distributions = prediction_and_true[\"true_distributions\"]\n",
        "pred_distributions = prediction_and_true[\"predicted_distributions\"]\n",
        "\n",
        "true_labels = np.argmax(true_distributions, axis=1)\n",
        "predicted_labels = np.argmax(pred_distributions, axis=1)\n",
        "\n",
        "\n",
        "emotion_labels = [\n",
        "    \"angry\", \"happy\", \"sad\", \"neutral\", \"fear_surprise\", \"disgust\"\n",
        "]\n",
        "\n",
        "\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=emotion_labels)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix with Emotion Labels\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ABXSLGzcK34q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top-2 predicted classes for each sample\n",
        "top2_preds = np.argsort(pred_distributions, axis=1)[:, -2:]\n",
        "\n",
        "pred_labels_for_cm = [\n",
        "    true_labels[i] if true_labels[i] in top2_preds[i] else np.argmax(pred_distributions[i])\n",
        "    for i in range(len(true_labels))\n",
        "]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels_for_cm)\n",
        "\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=emotion_labels)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
        "plt.title(\"Top-2 Accuracy Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cvjM0aX2OSNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note idea grabbed from https://library.virginia.edu/data/articles/correlation-pearson-spearman-and-kendalls-tau\n",
        "import numpy as np\n",
        "from scipy.stats import kendalltau\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "threshold = 0.2\n",
        "taus = []\n",
        "print(f\"{len(true_distributions)}\")\n",
        "for i in range(len(true_distributions)):\n",
        "    overthreshold_indexes = np.where(true_distributions[i] > threshold)[0]\n",
        "\n",
        "    if len(overthreshold_indexes) < 2:\n",
        "        continue\n",
        "    true_vals = true_distributions[i][overthreshold_indexes]\n",
        "    pred_vals = pred_distributions[i][overthreshold_indexes]\n",
        "\n",
        "    tau, _ = kendalltau(true_vals, pred_vals)\n",
        "    taus.append(tau)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(taus, bins=20, color='skyblue', edgecolor='black')\n",
        "plt.xlabel(\"Kendall Tau Rank Correlation\")\n",
        "plt.ylabel(\"Number of samples\")\n",
        "plt.title(\"Rank Correlation for Significant Emotions\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average Kendall Tau: {np.mean(taus):.3f}\")\n",
        "print(f\"Std Kendall Tau: {np.std(taus):.3f}\")\n"
      ],
      "metadata": {
        "id": "AARCM5DCS42V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Threshold for significant emotions\n",
        "threshold = 0.20\n",
        "\n",
        "num_emotions = true_distributions.shape[1]\n",
        "emotion_labels = [\"angry\", \"happy\", \"sad\", \"neutral\", \"fear_surprise\", \"disgust\"]\n",
        "\n",
        "exact_matches = []\n",
        "missed_counts = np.zeros(num_emotions)\n",
        "extra_counts = np.zeros(num_emotions)\n",
        "\n",
        "for i in range(len(true_distributions)):\n",
        "    if i == 200:\n",
        "      print (true_distributions[i])\n",
        "      print (pred_distributions[i])\n",
        "    true_overthreshold = set(np.where(true_distributions[i] > threshold)[0])\n",
        "    pred_overthreshold = set(np.where(pred_distributions[i] > threshold)[0])\n",
        "\n",
        "    exact_matches.append(true_overthreshold == pred_overthreshold)\n",
        "\n",
        "    missed = true_overthreshold - pred_overthreshold\n",
        "    extra = pred_overthreshold - true_overthreshold\n",
        "\n",
        "    for idx in missed:\n",
        "        missed_counts[idx] += 1\n",
        "    for idx in extra:\n",
        "        extra_counts[idx] += 1\n",
        "\n",
        "\n",
        "exact_matches = np.array(exact_matches)\n",
        "\n",
        "\n",
        "exact_match_percent = exact_matches.mean() * 100\n",
        "print(f\"Exact set match (threshold={threshold}): {exact_match_percent:.2f}%\")\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=emotion_labels, y=missed_counts, color=\"red\", label=\"Missed\")\n",
        "sns.barplot(x=emotion_labels, y=extra_counts, color=\"blue\", alpha=0.5, label=\"Extra\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Missed vs Extra Predicted Emotions per Class\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qzj_532YS57n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DL84UwH1qMBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}